# -*- coding: utf-8 -*-
__author__ = 'a.melnikov'

from south.utils import datetime_utils as datetime
from south.db import db
from south.v2 import DataMigration
from django.db import models
import os
from lyrics.models import Song, IndexElement

from HTMLParser import HTMLParser
from pymorphy import get_morph  # Морфологический анализатор https://pythonhosted.org/pymorphy/intro.html
import argparse

morph = get_morph('/home/antre/pymorphy_dicts/')    # Директория со словарями для pymorphy
RUS_LETTERS = "ЙЦУКЕНГШЩЗХЪФЫВАПРОЛДЖЭЯЧСМИТЬБЮЁ".decode('utf-8')

set_of_marked_words = set()     # слова, которые можно извлечь из запроса, включая синонимы
                                # нужны для выделения в сниппете
encoding = 0


#====================================================================================Операции над постинг-листами=======
class ExtendedPostingList():
    """
    Оболочка над постинг-листом, позволяет строить дополнение, чтобы не создавать огромный постинг-лист для операции NOT
    """
    def __init__(self, posting_list, freq, trend=True):
        self.posting_list = posting_list    # постинг-лист
        self.freq = freq                    # частота
        self.trend = trend                  # тренд: если False - то реальный постинг-лист - дополнение указанного

    def __repr__(self):
        return repr((self.posting_list, self.freq, self.trend))

    def build_supplementation(self):
        """
        Операция NOT
        """
        self.trend = not self.trend
        return self

    def add_element(self, e):
        self.posting_list.append(e)
        self.freq += 1

    def pop(self):
        self.posting_list.pop(0)
        self.freq -= 1

    def fst(self):
        return self.posting_list[0]


def intersect(pl1, pl2):
    """
    Пересечение двух постинг-листов
    """
    #print "int inp"
    #print pl1.posting_list
    #print pl2.posting_list

    pl = ExtendedPostingList(list(), 0, pl1.trend)
    while pl1.freq > 0 and pl2.freq > 0:
        pl1_fst = pl1.posting_list[0]
        pl2_fst = pl2.posting_list[0]
        if pl1_fst == pl2_fst:
            pl.add_element(pl1_fst)
            pl1.pop()
            pl2.pop()
        elif pl1_fst < pl2_fst:
            pl1.pop()
        else:
            pl2.pop()

    #print "int out"
    #print pl.posting_list
    return pl


def union(pl1, pl2):
    """
    Объединение двух постинг-листов
    """
    #print "int inp"
    #print pl1.posting_list
    #print pl2.posting_list

    pl = ExtendedPostingList(list(), 0, pl1.trend)
    while pl1.freq > 0 and pl2.freq > 0:
        pl1_fst = pl1.posting_list[0]
        pl2_fst = pl2.posting_list[0]
        if pl1_fst == pl2_fst:
            pl.add_element(pl1_fst)
            pl1.pop()
            pl2.pop()
        elif pl1_fst < pl2_fst:
            pl.add_element(pl1_fst)
            pl1.pop()
        else:
            pl.add_element(pl2_fst)
            pl2.pop()
    while pl1.freq > 0:
        pl.add_element(pl1.posting_list[0])
        pl1.pop()
    while pl2.freq > 0:
        pl.add_element(pl2.posting_list[0])
        pl2.pop()

    #print "int out"
    #print pl.posting_list
    return pl


def diff(pl1, pl2):
    """
    Разность двух постинг-листов, используется для x AND NOT y
    """
    #print "dif inp"
    #print pl1.posting_list
    #print pl2.posting_list

    pl = ExtendedPostingList(list(), 0, pl1.trend)
    while pl1.freq > 0 and pl2.freq > 0:
        pl1_fst = pl1.posting_list[0]
        pl2_fst = pl2.posting_list[0]
        if pl1_fst == pl2_fst:
            pl1.pop()
            pl2.pop()
        elif pl1_fst < pl2_fst:
            pl.add_element(pl1_fst)
            pl1.pop()
        else:
            pl2.pop()

    while pl1.freq > 0:
        pl.add_element(pl1.posting_list[0])
        pl1.pop()

    #print "dif out"
    #print pl.posting_list
    return pl

#===========================================================================================================Парсинг=====

#   Такая получается БНФ:
#   exp ::= term {OR term}
#   term ::= factor {AND factor}
#   factor := NOT factor | word | (exp)


def parse_exp(s):
    """
    a OR b OR NOT c OR NOT d
    :param s:
    :return:
    """
    s = s.lstrip().rstrip()
    print "EXP " + s
    term_list = s.split("OR")

    l1 = list()     # прямой тренд
    l2 = list()     # дополнения

    # Распределим постинг-листы по тренду
    for term in term_list:
        new_pl = parse_term(term)
        if new_pl.trend:
            l1.append(new_pl)
        else:
            l2.append(new_pl)

    # OR(NOT xi) = NOT пересечения списков
    l2 = sorted(l2, key=lambda pl: pl.freq)
    while len(l2) > 1:
        l2.insert(0, intersect(l2.pop(0), l2.pop(0)))

    # OR(xi) = Объединение списков
    l1 = sorted(l1, key=lambda pl: -pl.freq)
    while len(l1) > 1:
        l1.insert(0, union(l1.pop(0), l1.pop(0)))

    if len(l1) == 0 and len(l2) == 0:
        return ExtendedPostingList(list(), 0, False)

    if len(l2) == 0:
        return l1.pop()

    if len(l1) == 0:
        return l2.pop()

    # a OR NOT b = NOT (b - a)
    return diff(l2.pop(), l1.pop())


def parse_term(s):
    """
    a AND b AND c AND NOT d AND NOT e
    :param s:
    :return:
    """
    s = s.lstrip().rstrip()
    print "TERM " + s
    factor_list = s.split("AND")
    l1 = list()     # прямой тренд
    l2 = list()     # дополнения

    # Распределим постинг-листы по тренду
    for factor in factor_list:
        new_pl = parse_factor(factor)
        if new_pl.trend:
            l1.append(new_pl)
        else:
            l2.append(new_pl)

    # AND(xi) = Пересечение списков
    l1 = sorted(l1, key=lambda pl: pl.freq)
    while len(l1) > 1:
        l1.insert(0, intersect(l1.pop(0), l1.pop(0)))

    # AND(NOT xi) = NOT объединения списков
    l2 = sorted(l2, key=lambda pl: -pl.freq)
    while len(l2) > 1:
        l2.insert(0, union(l2.pop(0), l2.pop(0)))

    if len(l1) == 0 and len(l2) == 0:
        return ExtendedPostingList(list(), 0)

    if len(l2) == 0:
        return l1.pop()

    if len(l1) == 0:
        return l2.pop()

    # Сольем два суммарных списка x AND NOT y
    return diff(l1.pop(), l2.pop())


def parse_factor(s):
    s = s.lstrip().rstrip()
    if len(s) == 0:
        raise IndexError
    print "FACTOR " + s
    if s[0] == '(' and s[-1] == ')':
        s = s[1:-1]
        return parse_exp(up(s))
    elif s[0:3] == 'NOT':
        s = s[3:]
        return parse_factor(s).build_supplementation()
    else:
        words, freq = find_word(s)
        return ExtendedPostingList(words, freq)

#    def handle_data(self, data=''):
#        """
#        Ищем абзац по обратному индексу
#        """
#        if self.in_dd_tag and self.limit > 0:
#            if self.ex_page_list.trend:
#                if self.ex_page_list.freq > 0 and self.ex_page_list.posting_list[0] == self.page:
#                    s = data.decode('koi8-r')
#
#                    print self.page
#                    print mark_terms_in_snippet(s)
#
#                    self.ex_page_list.pop()
#                    self.limit -= 1
#            else:
#                if self.ex_page_list.freq > 0 and self.ex_page_list.posting_list[0] == self.page:
#                    self.ex_page_list.pop()
#                else:
#                    # номер текущей страницы меньше первого, которого не нужно включать
#                    # или не осталось запрещенных страниц
#                    s = data.decode('koi8-r')
#
#                    print self.page
#                    print mark_terms_in_snippet(s)
#
#                    self.limit -= 1


def mark_terms_in_snippet(s):
    """
    Парсинг и выделение слов в абзаце
    :param s: абзац
    глоб. set_of_marked_terms: термы, которые надо выделить
    :return строка с выделенными токенами
    """
    res = ""
    word = ""
    word_started = False

    s += " "
    for sign in s:
        if word_started:
            if sign.upper() in (RUS_LETTERS + '-'.decode('utf-8')):
                # Слово продолжается
                word += sign
            else:
                # Слово закончилось
                # Надо ли его выделить или оставить в прежнем виде
                set_of_normalized = morph.normalize(word.upper())       # Здесь на совсем плохих токенах бывают косяки

                if type(set_of_normalized).__name__ == 'set' and set_of_normalized & set_of_marked_words:
                    res += word.upper()
                else:
                    res += word
                word_started = False
                res += sign
        else:
            if sign.upper() in RUS_LETTERS:
                # Слово началось
                word = sign
                word_started = True
            else:
                res += sign

    return res


def find_word(word):
    """
    Для всех вариантов нормализации токена выведем список всех похожих термов, по нему - все контексты
    :param word: токен
    :return постинг-лист, частота
    """
    set_of_contexts = set()
    for term in morph.normalize(word):
        print "> н.ф. "
        print term

        # TODO check, select related
        index_element_from_db = IndexElement.objects.filter(term=term)
        for e in index_element_from_db:
            print "-----------------найдено----------------"
            set_of_marked_words.add(e.term)
            for s in Song.objects.filter(indexelement=e):
                set_of_contexts.add(s.id)

               # Добавим не только вариант нормализации, но и постинг-листы всех синонимов

                #for syn in note.synonyms:
                #    set_of_marked_words.add(syn.term)
                #    for s_e in get_posting_list(syn.posting_list):                                            #
                #        set_of_contexts.add(s_e)
    print "Найдено страниц для всех вариантов нормализации, включая синонимы: " + str(len(set_of_contexts))
    page_list = sorted(set_of_contexts)

    return page_list, len(page_list)


def get_posting_list(posting_list):
    global encoding
    if encoding == 0:
        return posting_list


def up(s):
    """
    Преобразования строки для корректной работы с уровнями вложенности
    В верхнем регистре останутся операции только верхнего уровня, по ним парсер будет разбивать строку
    """
    res = ""
    in_brakes = 0
    for symb in s:
        if in_brakes == 0:
            res += symb.upper()
        else:
            res += symb.lower()
        if symb == '(':
            in_brakes += 1
        if symb == ')':
            in_brakes -= 1
    return res


def parse_args():
    """
    Парсинг аргументов командной строки
    """
    c_l_parser = argparse.ArgumentParser(description='Булев поиск')
    c_l_parser.add_argument('-l', type=str, dest='line', help='Разбираемая строка', required=True)
    c_l_parser.add_argument('-n', dest='limit', type=int, default=100500, help='Лимит на результат')
    c_l_parser.add_argument('-e', dest='encoding', type=int, default=0, help='Кодировка постинга:\t1 s9\t 2 vb')
    return c_l_parser.parse_args()


def main_():
    global encoding

    #parser = MyHTMLParserForPageSearch()
    #args = parse_args()

    #encoding = args.encoding
    encoding = 0

    w = "кто AND ищет"                                                                                   #TODO
    #parser.limit = args.limit

    try:
        #parser.ex_page_list = parse_exp(up(w.decode('utf-8').lstrip().rstrip()))
        aaa = parse_exp(up(w.decode('utf-8').lstrip().rstrip()))
    except IndexError:
        print "Что-то не так с входными данными"
        return
    print ">>>>>>>>>>>>>>>>RESULT>>>>>>>>>>>>>>>>>>>>>>"                                                #TODO
    for i in aaa.posting_list:
        try:
            print Song.objects.get(id=i).lyrics
        except Song.DoesNotExist:
            print "NOT OK"


class Migration(DataMigration):

    def forwards(self, orm):
        "Write your forwards methods here."
        main_()

    def backwards(self, orm):
        "Write your backwards methods here."
        # Ничего

    models = {
        u'lyrics.indexelement': {
            'Meta': {'object_name': 'IndexElement'},
            u'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),
            'song': ('django.db.models.fields.related.ManyToManyField', [], {'to': u"orm['lyrics.Song']", 'symmetrical': 'False'}),
            'term': ('django.db.models.fields.CharField', [], {'unique': 'True', 'max_length': '100'})
        },
        u'lyrics.song': {
            'Meta': {'ordering': "['title']", 'object_name': 'Song'},
            'aid': ('django.db.models.fields.IntegerField', [], {'unique': 'True'}),
            'artist': ('django.db.models.fields.CharField', [], {'max_length': '128'}),
            'duration': ('django.db.models.fields.IntegerField', [], {}),
            u'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),
            'lyrics': ('django.db.models.fields.TextField', [], {}),
            'title': ('django.db.models.fields.CharField', [], {'max_length': '128'}),
            'url': ('django.db.models.fields.URLField', [], {'max_length': '100'})
        }
    }

    complete_apps = ['lyrics']
    symmetrical = True
